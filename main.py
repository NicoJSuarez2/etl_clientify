from src.extract.clientify_api import *
from src.extract.extract import *
from src.extract.transform import transform_dataset
from src.extract.load import load_to_csv
from src.transform.utils import *
from src.load.load import ejecucion_carga
import sys


def run_extract(logger, full_load: bool = True):
    # Extraer todos los datos
    logger.info("Iniciando extracciÃ³n de datos...")
    try:
        all_data = extract_all(logger, full_load=full_load)
    except Exception as e:
        logger.info(f"âŒ Error en extracciÃ³n: {e}")
        return
    if not all_data:
        logger.info("âš ï¸ all_data estÃ¡ vacÃ­o. No hay datasets para transformar/guardar.")
        return
    # Transformar y guardar
    for name, df in all_data.items():
        logger.info(f"\nðŸ”„ Transformando {name}...")
        try:
            df_transformed = transform_dataset(df, name)
            if df_transformed is None:
                logger.info(f"âš ï¸ transform_dataset devolviÃ³ None para {name}, se omite.")
                continue
            # Si es un DataFrame, opcionalmente comprobar si estÃ¡ vacÃ­o
            try:
                is_empty = getattr(df_transformed, "empty", False)
                if is_empty:
                    logger.info(
                        f"âš ï¸ El DataFrame transformado de {name} estÃ¡ vacÃ­o, se omite."
                    )
                    continue
            except Exception:
                pass
            # Guardar en process/
            # load_to_parquet(df_transformed, name)
            load_to_csv(logger, df_transformed, name)
            logger.info(f"âœ… {name} procesado y guardado.")
        except Exception as e:
            logger.info(f"âŒ Error procesando {name}: {e}")


def run_extract_times(logger):
    """
    FunciÃ³n especÃ­fica para extraer y guardar los tiempos de los deals.
    """
    logger.info(f"\nðŸ”„ Transformando deal_times...")
    #df_times = extraccion_tiempos(logger)
    #transform_dataset(df_times, "deal_times")
    #load_to_csv(logger, df_times, "deal_times")
    logger.info(f"âœ… deal_times procesado y guardado.")


def run_transform(logger):
    """
    FunciÃ³n principal para cargar y limpiar archivos CSV en una carpeta dada.
    """
    logger.info(f"\nIniciando transfomraciones en: data/raw")
    limpiar_archivos(logger)
    logger.info("\nLimpieza completada.")

def run_load(logger):
    """
    FunciÃ³n principal para cargar archivos Parquet desde data/stage a la base de datos SQL.
    """
    logger.info(f"\nIniciando carga de datos a la base de datos SQL...")
    ejecucion_carga(logger)
    logger.info("\nCarga completada.")

# =============================
# EJECUCIÃ“N
# =============================
if __name__ == "__main__":
    modo = sys.argv[1] if len(sys.argv) > 1 else "full"

    logger = config_logger()

    if modo == "1":
        run_extract(logger, full_load=False)
        run_transform(logger)
        run_load(logger)

    elif modo == "2":
        run_extract(logger, full_load=False)
        run_extract_times(logger)
        run_transform(logger)
        run_load(logger)

    elif modo == "3":
        run_transform(logger)
        run_load(logger)

    logger.info("Proceso ETL completado.")
